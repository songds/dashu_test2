15:07:33.404 INFO  [] StartupInfoLogger.logStarting:48 Starting Runner on DS-TS-0358 with PID 10000 (D:\Workspace\spring_boot_kafka_test\bin started by ex-songdeshun in D:\Workspace\spring_boot_kafka_test)
15:07:33.404 INFO  [] SpringApplication.logStartupProfileInfo:659 No active profile set, falling back to default profiles: default
15:07:33.451 INFO  [] AbstractApplicationContext.prepareRefresh:581 Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2abf4075: startup date [Wed Sep 27 15:07:33 CST 2017]; root of context hierarchy
15:07:34.170 WARN  [] AutoProxyRegistrar.registerBeanDefinitions:79 AutoProxyRegistrar was imported but no annotations were found having both 'mode' and 'proxyTargetClass' attributes of type AdviceMode and boolean respectively. This means that auto proxy creator registration and configuration may not have occurred as intended, and components may not be proxied as expected. Check to ensure that AutoProxyRegistrar has been @Import'ed on the same class where these annotations are declared; otherwise remove the import of AutoProxyRegistrar altogether.
15:07:34.354 INFO  [] RepositoryConfigurationDelegate.multipleStoresDetected:166 Multiple Spring Data modules found, entering strict repository configuration mode!
15:07:34.448 INFO  [] RepositoryConfigurationDelegate.multipleStoresDetected:166 Multiple Spring Data modules found, entering strict repository configuration mode!
15:07:34.649 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'com.dashuf.core.common.configuration.CommonConfiguration' of type [class com.dashuf.core.common.configuration.CommonConfiguration$$EnhancerBySpringCGLIB$$2bc26ee3] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:07:34.665 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'com.dashuf.core.event.configuration.EventConfiguration' of type [class com.dashuf.core.event.configuration.EventConfiguration$$EnhancerBySpringCGLIB$$88fc531b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:07:34.675 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [class org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$5c9ed6c0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:07:34.745 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$88ecc53d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:07:35.051 INFO  [] Xnio.<clinit>:99 XNIO version 3.3.6.Final
15:07:35.063 INFO  [] NioXnio.<clinit>:55 XNIO NIO Implementation Version 3.3.6.Final
15:07:35.131 WARN  [] Bootstrap.handleDeployment:67 UT026009: XNIO worker was not set on WebSocketDeploymentInfo, the default worker will be used
15:07:35.131 WARN  [] Bootstrap.handleDeployment:76 UT026010: Buffer pool was not set on WebSocketDeploymentInfo, the default pool will be used
15:07:35.143 INFO  [] ServletContextImpl.log:313 Initializing Spring embedded WebApplicationContext
15:07:35.143 INFO  [] EmbeddedWebApplicationContext.prepareEmbeddedWebApplicationContext:276 Root WebApplicationContext: initialization completed in 1692 ms
15:07:35.304 INFO  [] ServletRegistrationBean.onStartup:190 Mapping servlet: 'dispatcherServlet' to [/]
15:07:35.308 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'metricFilter' to: [/*]
15:07:35.308 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'characterEncodingFilter' to: [/*]
15:07:35.309 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
15:07:35.309 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'httpPutFormContentFilter' to: [/*]
15:07:35.309 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'requestContextFilter' to: [/*]
15:07:35.309 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'webRequestLoggingFilter' to: [/*]
15:07:35.309 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'applicationContextIdFilter' to: [/*]
15:07:35.439 INFO  [] LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory:334 Building JPA container EntityManagerFactory for persistence unit 'default'
15:07:35.459 INFO  [] LogHelper.logPersistenceUnitInformation:31 HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
15:07:35.499 INFO  [] Version.logVersion:37 HHH000412: Hibernate Core {5.0.9.Final}
15:07:35.499 INFO  [] Environment.<clinit>:213 HHH000206: hibernate.properties not found
15:07:35.509 INFO  [] Environment.buildBytecodeProvider:317 HHH000021: Bytecode provider name : javassist
15:07:35.536 INFO  [] JavaReflectionManager.<clinit>:66 HCANN000001: Hibernate Commons Annotations {5.0.1.Final}
15:07:35.856 INFO  [] Dialect.<init>:156 HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
15:07:35.986 INFO  [] SchemaValidator.validate:69 HHH000229: Running schema validator
15:07:36.006 INFO  [] AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory:382 Initialized JPA EntityManagerFactory for persistence unit 'default'
15:07:36.096 WARN  [] ServiceInstance.init:87 Instance name is empty, IP[10.1.113.233] will instead of it.
15:07:36.376 INFO  [] RequestMappingHandlerAdapter.initControllerAdviceCache:534 Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2abf4075: startup date [Wed Sep 27 15:07:33 CST 2017]; root of context hierarchy
15:07:36.435 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
15:07:36.435 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
15:07:36.465 INFO  [] AbstractUrlHandlerMapping.registerHandler:354 Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
15:07:36.465 INFO  [] AbstractUrlHandlerMapping.registerHandler:354 Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
15:07:36.495 INFO  [] AbstractUrlHandlerMapping.registerHandler:354 Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
15:07:36.756 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:07:36.756 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/health || /health.json],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(java.security.Principal)
15:07:36.756 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
15:07:36.756 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:07:36.756 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:07:36.756 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:07:36.756 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
15:07:36.756 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/env || /env.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:07:36.756 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
15:07:36.756 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
15:07:36.756 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:07:36.756 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/info || /info.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:07:36.756 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:07:36.756 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:07:36.905 WARN  [] RedisStarterDeprecationWarningAutoConfiguration.logWarning:43 spring-boot-starter-redis is deprecated as of Spring Boot 1.4, please migrate to spring-boot-starter-data-redis
15:07:36.965 INFO  [] MBeanExporter.afterSingletonsInstantiated:431 Registering beans for JMX exposure on startup
15:07:36.975 INFO  [] DefaultLifecycleProcessor$LifecycleGroup.start:341 Starting beans in phase 0
15:07:36.985 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:07:37.005 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:07:37.025 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:07:37.025 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:07:37.025 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:07:37.025 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:07:37.025 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:07:37.025 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:07:37.025 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:07:37.035 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:07:37.035 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:07:37.035 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:07:37.035 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:07:37.035 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:07:37.035 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:07:37.035 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:07:37.035 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:07:37.045 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:07:37.045 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:07:37.045 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:07:37.115 WARN  [] NetworkClient$DefaultMetadataUpdater.handleResponse:600 Error while fetching metadata with correlation id 1 : {KafKaTestApiTestBegin=LEADER_NOT_AVAILABLE}
15:07:37.115 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:07:37.115 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:07:37.115 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:07:37.115 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:07:37.125 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 1
15:07:37.125 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:07:37.125 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:07:37.135 INFO  [] UndertowEmbeddedServletContainer.start:214 Undertow started on port(s) 9050 (http)
15:07:37.135 INFO  [] StartupInfoLogger.logStarted:57 Started Runner in 4.06 seconds (JVM running for 4.364)
15:07:37.155 WARN  [] NetworkClient$DefaultMetadataUpdater.handleResponse:600 Error while fetching metadata with correlation id 1 : {KafKaTestApiTestBegin=LEADER_NOT_AVAILABLE}
15:07:37.165 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:07:37.165 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:07:37.165 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:07:37.165 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:07:37.165 WARN  [] NetworkClient$DefaultMetadataUpdater.handleResponse:600 Error while fetching metadata with correlation id 1 : {KafKaTestApiTestBegin=LEADER_NOT_AVAILABLE}
15:07:37.165 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:07:37.165 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:07:37.165 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:07:37.165 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:07:37.195 WARN  [] NetworkClient$DefaultMetadataUpdater.handleResponse:600 Error while fetching metadata with correlation id 1 : {KafKaTestApiTestBegin=LEADER_NOT_AVAILABLE}
15:07:37.195 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:07:37.195 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:07:37.195 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:07:37.195 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:07:37.195 WARN  [] NetworkClient$DefaultMetadataUpdater.handleResponse:600 Error while fetching metadata with correlation id 1 : {KafKaTestApiTestBegin=LEADER_NOT_AVAILABLE}
15:07:37.195 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:07:37.195 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:07:37.195 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:07:37.195 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:07:40.128 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:07:40.129 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:07:40.129 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:07:40.139 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 2
15:07:40.139 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 2
15:07:40.139 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 2
15:07:40.140 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 2
15:07:40.139 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 2
15:07:40.140 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:07:40.140 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:07:40.140 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:07:40.141 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:07:40.141 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:07:40.141 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:07:40.141 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:07:40.141 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:07:40.141 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:07:40.142 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:09:06.891 INFO  [] StartupInfoLogger.logStarting:48 Starting Runner on DS-TS-0358 with PID 11184 (D:\Workspace\spring_boot_kafka_test\bin started by ex-songdeshun in D:\Workspace\spring_boot_kafka_test)
15:09:06.894 INFO  [] SpringApplication.logStartupProfileInfo:659 No active profile set, falling back to default profiles: default
15:09:06.945 INFO  [] AbstractApplicationContext.prepareRefresh:581 Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2abf4075: startup date [Wed Sep 27 15:09:06 CST 2017]; root of context hierarchy
15:09:08.104 WARN  [] AutoProxyRegistrar.registerBeanDefinitions:79 AutoProxyRegistrar was imported but no annotations were found having both 'mode' and 'proxyTargetClass' attributes of type AdviceMode and boolean respectively. This means that auto proxy creator registration and configuration may not have occurred as intended, and components may not be proxied as expected. Check to ensure that AutoProxyRegistrar has been @Import'ed on the same class where these annotations are declared; otherwise remove the import of AutoProxyRegistrar altogether.
15:09:08.278 INFO  [] RepositoryConfigurationDelegate.multipleStoresDetected:166 Multiple Spring Data modules found, entering strict repository configuration mode!
15:09:08.378 INFO  [] RepositoryConfigurationDelegate.multipleStoresDetected:166 Multiple Spring Data modules found, entering strict repository configuration mode!
15:09:08.618 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'com.dashuf.core.common.configuration.CommonConfiguration' of type [class com.dashuf.core.common.configuration.CommonConfiguration$$EnhancerBySpringCGLIB$$2bc26ee3] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:09:08.628 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'com.dashuf.core.event.configuration.EventConfiguration' of type [class com.dashuf.core.event.configuration.EventConfiguration$$EnhancerBySpringCGLIB$$88fc531b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:09:08.628 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [class org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$5c9ed6c0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:09:08.698 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$88ecc53d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:09:09.008 INFO  [] Xnio.<clinit>:99 XNIO version 3.3.6.Final
15:09:09.028 INFO  [] NioXnio.<clinit>:55 XNIO NIO Implementation Version 3.3.6.Final
15:09:09.098 WARN  [] Bootstrap.handleDeployment:67 UT026009: XNIO worker was not set on WebSocketDeploymentInfo, the default worker will be used
15:09:09.098 WARN  [] Bootstrap.handleDeployment:76 UT026010: Buffer pool was not set on WebSocketDeploymentInfo, the default pool will be used
15:09:09.108 INFO  [] ServletContextImpl.log:313 Initializing Spring embedded WebApplicationContext
15:09:09.110 INFO  [] EmbeddedWebApplicationContext.prepareEmbeddedWebApplicationContext:276 Root WebApplicationContext: initialization completed in 2165 ms
15:09:09.261 INFO  [] ServletRegistrationBean.onStartup:190 Mapping servlet: 'dispatcherServlet' to [/]
15:09:09.261 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'metricFilter' to: [/*]
15:09:09.261 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'characterEncodingFilter' to: [/*]
15:09:09.261 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
15:09:09.261 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'httpPutFormContentFilter' to: [/*]
15:09:09.261 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'requestContextFilter' to: [/*]
15:09:09.271 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'webRequestLoggingFilter' to: [/*]
15:09:09.271 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'applicationContextIdFilter' to: [/*]
15:09:09.411 INFO  [] LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory:334 Building JPA container EntityManagerFactory for persistence unit 'default'
15:09:09.421 INFO  [] LogHelper.logPersistenceUnitInformation:31 HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
15:09:09.471 INFO  [] Version.logVersion:37 HHH000412: Hibernate Core {5.0.9.Final}
15:09:09.471 INFO  [] Environment.<clinit>:213 HHH000206: hibernate.properties not found
15:09:09.471 INFO  [] Environment.buildBytecodeProvider:317 HHH000021: Bytecode provider name : javassist
15:09:09.501 INFO  [] JavaReflectionManager.<clinit>:66 HCANN000001: Hibernate Commons Annotations {5.0.1.Final}
15:09:09.878 INFO  [] Dialect.<init>:156 HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
15:09:10.010 INFO  [] SchemaValidator.validate:69 HHH000229: Running schema validator
15:09:10.037 INFO  [] AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory:382 Initialized JPA EntityManagerFactory for persistence unit 'default'
15:09:10.151 WARN  [] ServiceInstance.init:87 Instance name is empty, IP[10.1.113.233] will instead of it.
15:09:10.459 INFO  [] RequestMappingHandlerAdapter.initControllerAdviceCache:534 Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2abf4075: startup date [Wed Sep 27 15:09:06 CST 2017]; root of context hierarchy
15:09:10.519 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
15:09:10.521 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
15:09:10.547 INFO  [] AbstractUrlHandlerMapping.registerHandler:354 Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
15:09:10.547 INFO  [] AbstractUrlHandlerMapping.registerHandler:354 Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
15:09:10.573 INFO  [] AbstractUrlHandlerMapping.registerHandler:354 Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
15:09:10.854 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
15:09:10.854 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/env || /env.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:09:10.854 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:09:10.854 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/health || /health.json],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(java.security.Principal)
15:09:10.854 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:09:10.854 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
15:09:10.854 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:09:10.854 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:09:10.854 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
15:09:10.854 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
15:09:10.854 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:09:10.854 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:09:10.870 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:09:10.870 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/info || /info.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:09:11.025 WARN  [] RedisStarterDeprecationWarningAutoConfiguration.logWarning:43 spring-boot-starter-redis is deprecated as of Spring Boot 1.4, please migrate to spring-boot-starter-data-redis
15:09:11.095 INFO  [] MBeanExporter.afterSingletonsInstantiated:431 Registering beans for JMX exposure on startup
15:09:11.105 INFO  [] DefaultLifecycleProcessor$LifecycleGroup.start:341 Starting beans in phase 0
15:09:11.115 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:09:11.135 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:09:11.155 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:09:11.156 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:09:11.157 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:09:11.157 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:09:11.157 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:09:11.157 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:09:11.157 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:09:11.157 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:09:11.157 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:09:11.157 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:09:11.167 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:09:11.167 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:09:11.167 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:09:11.167 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:09:11.167 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:09:11.177 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:09:11.177 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:09:11.177 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:09:11.197 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:09:11.197 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:09:11.197 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:09:11.197 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:09:11.207 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:09:11.207 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:09:11.207 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:09:11.207 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:09:11.217 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:09:11.227 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 5
15:09:11.227 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [KafKaTestApiTestBegin-2] for group Spring_boot_kafka_test
15:09:11.227 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 5
15:09:11.227 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [KafKaTestApiTestBegin-1, KafKaTestApiTestBegin-0] for group Spring_boot_kafka_test
15:09:11.257 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[KafKaTestApiTestBegin-2]
15:09:11.257 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[KafKaTestApiTestBegin-1, KafKaTestApiTestBegin-0]
15:09:11.277 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:09:11.277 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:09:11.277 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:09:11.277 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:09:11.277 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:09:11.277 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:09:11.277 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:09:11.277 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:09:11.287 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:09:11.287 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:09:11.287 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:09:11.287 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:09:11.287 INFO  [] UndertowEmbeddedServletContainer.start:214 Undertow started on port(s) 9050 (http)
15:09:11.287 INFO  [] StartupInfoLogger.logStarted:57 Started Runner in 4.745 seconds (JVM running for 5.052)
15:09:14.267 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [KafKaTestApiTestBegin-2] for group Spring_boot_kafka_test
15:09:14.267 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [KafKaTestApiTestBegin-1, KafKaTestApiTestBegin-0] for group Spring_boot_kafka_test
15:09:14.275 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[KafKaTestApiTestBegin-2]
15:09:14.275 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[KafKaTestApiTestBegin-1, KafKaTestApiTestBegin-0]
15:09:14.275 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:09:14.275 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:09:14.276 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 6
15:09:14.276 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 6
15:09:14.276 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 6
15:09:14.276 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 6
15:09:14.276 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 6
15:09:14.276 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:09:14.276 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [KafKaTestApiTestBegin-1] for group Spring_boot_kafka_test
15:09:14.276 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [KafKaTestApiTestBegin-2] for group Spring_boot_kafka_test
15:09:14.276 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:09:14.276 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [KafKaTestApiTestBegin-0] for group Spring_boot_kafka_test
15:09:14.276 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:09:14.276 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:09:14.276 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[KafKaTestApiTestBegin-2]
15:09:14.291 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[KafKaTestApiTestBegin-1]
15:09:14.291 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[KafKaTestApiTestBegin-0]
15:09:43.427 INFO  [T=eHBuIr9twc3dGygVNDkaKG] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:09:43.427 INFO  [T=eHBuIr9twc3dGygVNDkaKG] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=g71Yq7iKm3ZliLbqTimLb0, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=ff05qiAlj8Y1P3rtDU4c5Y, sourceId=ff05qiAlj8Y1P3rtDU4c5Y, scenario=KafKaTestApiTestBegin]
15:09:43.438 INFO  [T=eHBuIr9twc3dGygVNDkaKG] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:09:43.438 INFO  [T=eHBuIr9twc3dGygVNDkaKG] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[11ms] Result[{"soleCode":"DS01"}]
15:09:43.448 INFO  [T=eHBuIr9twc3dGygVNDkaKG] AbstractConfig.logAll:178 ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 1

15:09:43.457 INFO  [T=eHBuIr9twc3dGygVNDkaKG] AbstractConfig.logAll:178 ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 1

15:09:43.458 INFO  [T=eHBuIr9twc3dGygVNDkaKG] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:09:43.458 INFO  [T=eHBuIr9twc3dGygVNDkaKG] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:11:12.978 INFO  [] StartupInfoLogger.logStarting:48 Starting Runner on DS-TS-0358 with PID 10904 (D:\Workspace\spring_boot_kafka_test\bin started by ex-songdeshun in D:\Workspace\spring_boot_kafka_test)
15:11:12.990 INFO  [] SpringApplication.logStartupProfileInfo:659 No active profile set, falling back to default profiles: default
15:11:13.038 INFO  [] AbstractApplicationContext.prepareRefresh:581 Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@487db668: startup date [Wed Sep 27 15:11:13 CST 2017]; root of context hierarchy
15:11:13.860 WARN  [] AutoProxyRegistrar.registerBeanDefinitions:79 AutoProxyRegistrar was imported but no annotations were found having both 'mode' and 'proxyTargetClass' attributes of type AdviceMode and boolean respectively. This means that auto proxy creator registration and configuration may not have occurred as intended, and components may not be proxied as expected. Check to ensure that AutoProxyRegistrar has been @Import'ed on the same class where these annotations are declared; otherwise remove the import of AutoProxyRegistrar altogether.
15:11:14.111 INFO  [] RepositoryConfigurationDelegate.multipleStoresDetected:166 Multiple Spring Data modules found, entering strict repository configuration mode!
15:11:14.152 INFO  [] RepositoryConfigurationDelegate.multipleStoresDetected:166 Multiple Spring Data modules found, entering strict repository configuration mode!
15:11:14.390 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'com.dashuf.core.common.configuration.CommonConfiguration' of type [class com.dashuf.core.common.configuration.CommonConfiguration$$EnhancerBySpringCGLIB$$6aa83d74] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:11:14.404 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'com.dashuf.core.event.configuration.EventConfiguration' of type [class com.dashuf.core.event.configuration.EventConfiguration$$EnhancerBySpringCGLIB$$c7e221ac] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:11:14.412 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [class org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$9b84a551] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:11:14.510 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$c7d293ce] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:11:14.891 INFO  [] Xnio.<clinit>:99 XNIO version 3.3.6.Final
15:11:14.896 INFO  [] NioXnio.<clinit>:55 XNIO NIO Implementation Version 3.3.6.Final
15:11:14.968 WARN  [] Bootstrap.handleDeployment:67 UT026009: XNIO worker was not set on WebSocketDeploymentInfo, the default worker will be used
15:11:14.968 WARN  [] Bootstrap.handleDeployment:76 UT026010: Buffer pool was not set on WebSocketDeploymentInfo, the default pool will be used
15:11:14.980 INFO  [] ServletContextImpl.log:313 Initializing Spring embedded WebApplicationContext
15:11:14.980 INFO  [] EmbeddedWebApplicationContext.prepareEmbeddedWebApplicationContext:276 Root WebApplicationContext: initialization completed in 1942 ms
15:11:15.208 INFO  [] ServletRegistrationBean.onStartup:190 Mapping servlet: 'dispatcherServlet' to [/]
15:11:15.208 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'metricFilter' to: [/*]
15:11:15.208 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'characterEncodingFilter' to: [/*]
15:11:15.208 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
15:11:15.208 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'httpPutFormContentFilter' to: [/*]
15:11:15.208 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'requestContextFilter' to: [/*]
15:11:15.208 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'webRequestLoggingFilter' to: [/*]
15:11:15.208 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'applicationContextIdFilter' to: [/*]
15:11:15.411 INFO  [] LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory:334 Building JPA container EntityManagerFactory for persistence unit 'default'
15:11:15.426 INFO  [] LogHelper.logPersistenceUnitInformation:31 HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
15:11:15.489 INFO  [] Version.logVersion:37 HHH000412: Hibernate Core {5.0.9.Final}
15:11:15.489 INFO  [] Environment.<clinit>:213 HHH000206: hibernate.properties not found
15:11:15.489 INFO  [] Environment.buildBytecodeProvider:317 HHH000021: Bytecode provider name : javassist
15:11:15.520 INFO  [] JavaReflectionManager.<clinit>:66 HCANN000001: Hibernate Commons Annotations {5.0.1.Final}
15:11:15.915 INFO  [] Dialect.<init>:156 HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
15:11:16.067 INFO  [] SchemaValidator.validate:69 HHH000229: Running schema validator
15:11:16.098 INFO  [] AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory:382 Initialized JPA EntityManagerFactory for persistence unit 'default'
15:11:16.223 WARN  [] ServiceInstance.init:87 Instance name is empty, IP[10.1.113.233] will instead of it.
15:11:16.676 INFO  [] RequestMappingHandlerAdapter.initControllerAdviceCache:534 Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@487db668: startup date [Wed Sep 27 15:11:13 CST 2017]; root of context hierarchy
15:11:16.765 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
15:11:16.766 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
15:11:16.824 INFO  [] AbstractUrlHandlerMapping.registerHandler:354 Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
15:11:16.824 INFO  [] AbstractUrlHandlerMapping.registerHandler:354 Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
15:11:16.881 INFO  [] AbstractUrlHandlerMapping.registerHandler:354 Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
15:11:17.299 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:11:17.303 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/info || /info.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:11:17.304 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
15:11:17.304 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:11:17.304 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
15:11:17.304 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/env || /env.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:11:17.304 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:11:17.304 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/health || /health.json],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(java.security.Principal)
15:11:17.304 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:11:17.304 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:11:17.304 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:11:17.304 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
15:11:17.304 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
15:11:17.304 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:11:17.560 WARN  [] RedisStarterDeprecationWarningAutoConfiguration.logWarning:43 spring-boot-starter-redis is deprecated as of Spring Boot 1.4, please migrate to spring-boot-starter-data-redis
15:11:17.764 INFO  [] MBeanExporter.afterSingletonsInstantiated:431 Registering beans for JMX exposure on startup
15:11:17.764 INFO  [] DefaultLifecycleProcessor$LifecycleGroup.start:341 Starting beans in phase 0
15:11:17.779 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:11:17.810 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:11:17.826 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:11:17.826 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:11:17.826 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:11:17.826 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:11:17.826 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:11:17.826 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:11:17.842 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:11:17.842 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:11:17.842 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:11:17.842 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:11:17.842 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:11:17.842 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:11:17.842 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:11:17.842 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:11:17.842 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:11:17.842 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:11:17.857 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:11:17.857 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:11:17.885 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:11:17.885 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:11:17.885 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:11:17.885 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:11:17.895 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 8
15:11:17.895 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [KafKaTestApiTestBegin-1, KafKaTestApiTestBegin-2, KafKaTestApiTestBegin-0] for group Spring_boot_kafka_test
15:11:17.905 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[KafKaTestApiTestBegin-1, KafKaTestApiTestBegin-2, KafKaTestApiTestBegin-0]
15:11:17.965 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:11:17.965 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:11:17.965 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:11:17.965 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:11:17.965 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:11:17.965 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:11:17.965 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:11:17.965 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:11:17.965 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:11:17.965 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:11:17.965 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:11:17.965 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:11:17.975 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:11:17.975 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:11:17.975 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:11:17.975 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:11:17.985 INFO  [] UndertowEmbeddedServletContainer.start:214 Undertow started on port(s) 9050 (http)
15:11:17.985 INFO  [] StartupInfoLogger.logStarted:57 Started Runner in 5.391 seconds (JVM running for 5.835)
15:11:20.917 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [KafKaTestApiTestBegin-1, KafKaTestApiTestBegin-2, KafKaTestApiTestBegin-0] for group Spring_boot_kafka_test
15:11:20.936 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[KafKaTestApiTestBegin-1, KafKaTestApiTestBegin-2, KafKaTestApiTestBegin-0]
15:11:20.936 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:11:20.936 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 9
15:11:20.936 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:11:20.936 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 9
15:11:20.936 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 9
15:11:20.936 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:11:20.936 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [KafKaTestApiTestBegin-2] for group Spring_boot_kafka_test
15:11:20.936 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [KafKaTestApiTestBegin-0] for group Spring_boot_kafka_test
15:11:20.936 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 9
15:11:20.936 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 9
15:11:20.936 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:11:20.936 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [KafKaTestApiTestBegin-1] for group Spring_boot_kafka_test
15:11:20.936 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:11:20.936 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[KafKaTestApiTestBegin-2]
15:11:20.936 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[KafKaTestApiTestBegin-0]
15:11:20.936 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[KafKaTestApiTestBegin-1]
15:11:45.931 INFO  [T=gj0WwDrgOmBjxOzWmod2lV] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:11:45.932 INFO  [T=gj0WwDrgOmBjxOzWmod2lV] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=ccMxeyTja2hj84t1Fus8Ue, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=czcSR1sCvbXeNgsnht05n2, sourceId=czcSR1sCvbXeNgsnht05n2, scenario=KafKaTestApiTestBegin]
15:11:45.942 INFO  [T=gj0WwDrgOmBjxOzWmod2lV] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:11:45.943 INFO  [T=gj0WwDrgOmBjxOzWmod2lV] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[12ms] Result[{"soleCode":"DS01"}]
15:11:45.955 INFO  [T=gj0WwDrgOmBjxOzWmod2lV] AbstractConfig.logAll:178 ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 1

15:11:45.963 INFO  [T=gj0WwDrgOmBjxOzWmod2lV] AbstractConfig.logAll:178 ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 1

15:11:45.965 INFO  [T=gj0WwDrgOmBjxOzWmod2lV] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:11:45.965 INFO  [T=gj0WwDrgOmBjxOzWmod2lV] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:11:54.040 INFO  [T=c9FJikRPBFY864hqy5NfYL] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:11:54.041 INFO  [T=c9FJikRPBFY864hqy5NfYL] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=cEErJI4mi2N8hTPv6ofRlB, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=g2yrksF4XytgBPGmWBvz8M, sourceId=g2yrksF4XytgBPGmWBvz8M, scenario=KafKaTestApiTestBegin]
15:11:54.041 INFO  [T=c9FJikRPBFY864hqy5NfYL] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:11:54.041 INFO  [T=c9FJikRPBFY864hqy5NfYL] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:12:00.722 INFO  [T=frFxmHlaEszc3tm1Ta1U3o] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:00.723 INFO  [T=frFxmHlaEszc3tm1Ta1U3o] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=fqf7yZaeXZ6ciiVWKRO6NL, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=dHqDjP3yxbE1a0IUhMsWSy, sourceId=dHqDjP3yxbE1a0IUhMsWSy, scenario=KafKaTestApiTestBegin]
15:12:00.723 INFO  [T=frFxmHlaEszc3tm1Ta1U3o] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:00.723 INFO  [T=frFxmHlaEszc3tm1Ta1U3o] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:12:01.235 INFO  [T=cY3NzfvSxi63n1qE8rAazz] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:01.235 INFO  [T=cY3NzfvSxi63n1qE8rAazz] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=ee0Chr0eB0sbJtZDhNerhN, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=crRVPb2RgvffFfcv6eQGGN, sourceId=crRVPb2RgvffFfcv6eQGGN, scenario=KafKaTestApiTestBegin]
15:12:01.235 INFO  [T=cY3NzfvSxi63n1qE8rAazz] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:01.235 INFO  [T=cY3NzfvSxi63n1qE8rAazz] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:12:01.396 INFO  [T=d8KumNDQtux9GIEcRbdieD] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:01.396 INFO  [T=d8KumNDQtux9GIEcRbdieD] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=gazuW8YvVir9UzoEoWJtSu, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=btAxxdfQOhS6T8nCkYBbLU, sourceId=btAxxdfQOhS6T8nCkYBbLU, scenario=KafKaTestApiTestBegin]
15:12:01.396 INFO  [T=d8KumNDQtux9GIEcRbdieD] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:01.397 INFO  [T=d8KumNDQtux9GIEcRbdieD] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:12:01.581 INFO  [T=fmOpnRGZV450Y57dVdZL0X] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:01.581 INFO  [T=fmOpnRGZV450Y57dVdZL0X] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=dxIYaxAEqpehIUbWlEOxee, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=bSxc4Dy25ITlkVq0DORUD8, sourceId=bSxc4Dy25ITlkVq0DORUD8, scenario=KafKaTestApiTestBegin]
15:12:01.581 INFO  [T=fmOpnRGZV450Y57dVdZL0X] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:01.582 INFO  [T=fmOpnRGZV450Y57dVdZL0X] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:12:01.723 INFO  [T=g6Cp3HJOT2F4ONEd2hSonI] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:01.723 INFO  [T=g6Cp3HJOT2F4ONEd2hSonI] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=gcTtdSdZozthUQ7W3s9fCY, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=fTOsoQ3FxEy0inLUVEnOmf, sourceId=fTOsoQ3FxEy0inLUVEnOmf, scenario=KafKaTestApiTestBegin]
15:12:01.723 INFO  [T=g6Cp3HJOT2F4ONEd2hSonI] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:01.723 INFO  [T=g6Cp3HJOT2F4ONEd2hSonI] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:12:01.883 INFO  [T=dAYsHg8vkJy8IokWdt7FW1] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:01.883 INFO  [T=dAYsHg8vkJy8IokWdt7FW1] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=caostQ0zE641NYhGkgzTWh, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=dHwz1lFNtYV601jK7G35Wd, sourceId=dHwz1lFNtYV601jK7G35Wd, scenario=KafKaTestApiTestBegin]
15:12:01.883 INFO  [T=dAYsHg8vkJy8IokWdt7FW1] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:01.883 INFO  [T=dAYsHg8vkJy8IokWdt7FW1] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:12:02.065 INFO  [T=cVql592OnlK4y2oXS1J3Fk] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:02.065 INFO  [T=cVql592OnlK4y2oXS1J3Fk] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=b5sL9mxZhhohWl2p8RXaRp, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=e3REpwa7OmI4qTUGd4qJP6, sourceId=e3REpwa7OmI4qTUGd4qJP6, scenario=KafKaTestApiTestBegin]
15:12:02.065 INFO  [T=cVql592OnlK4y2oXS1J3Fk] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:02.065 INFO  [T=cVql592OnlK4y2oXS1J3Fk] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:12:02.231 INFO  [T=bQzs0rw6VyJ3Le0Ozqox6Z] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:02.231 INFO  [T=bQzs0rw6VyJ3Le0Ozqox6Z] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=eXqxpO6nve12eNqeJAZtM0, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=g499OGPO8m0hUgUjRaMSAs, sourceId=g499OGPO8m0hUgUjRaMSAs, scenario=KafKaTestApiTestBegin]
15:12:02.231 INFO  [T=bQzs0rw6VyJ3Le0Ozqox6Z] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:02.231 INFO  [T=bQzs0rw6VyJ3Le0Ozqox6Z] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:12:02.415 INFO  [T=efOt0JaeiBY9604oWOj6rI] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:02.415 INFO  [T=efOt0JaeiBY9604oWOj6rI] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=bI94uslloxq6qjr0hCSHFM, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=dIgz8v7bTnG41pQVgJVTlc, sourceId=dIgz8v7bTnG41pQVgJVTlc, scenario=KafKaTestApiTestBegin]
15:12:02.415 INFO  [T=efOt0JaeiBY9604oWOj6rI] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:02.415 INFO  [T=efOt0JaeiBY9604oWOj6rI] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:12:02.576 INFO  [T=cSLxJTa2tz55savKIrcKH5] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:02.576 INFO  [T=cSLxJTa2tz55savKIrcKH5] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=ctV3QXpKCMS0WMTEJyCwLu, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=dD1lzTvyaHegRKtO4KoHej, sourceId=dD1lzTvyaHegRKtO4KoHej, scenario=KafKaTestApiTestBegin]
15:12:02.576 INFO  [T=cSLxJTa2tz55savKIrcKH5] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:02.576 INFO  [T=cSLxJTa2tz55savKIrcKH5] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:12:03.718 INFO  [T=bG2AEFmHacqcHvwWCCFqYt] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:03.718 INFO  [T=bG2AEFmHacqcHvwWCCFqYt] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=bDszOrkj4hl8WwYAqvtqeN, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=dCpgcU9kKmygy9nGquw240, sourceId=dCpgcU9kKmygy9nGquw240, scenario=KafKaTestApiTestBegin]
15:12:03.718 INFO  [T=bG2AEFmHacqcHvwWCCFqYt] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:03.718 INFO  [T=bG2AEFmHacqcHvwWCCFqYt] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:12:03.901 INFO  [T=cq8vk8uAeIZ9RKjxp8AFd9] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:03.902 INFO  [T=cq8vk8uAeIZ9RKjxp8AFd9] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=brc7M8Lyd7V26LKEmJSvV4, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=eEDN4ULk7zj1EPdUMue88v, sourceId=eEDN4ULk7zj1EPdUMue88v, scenario=KafKaTestApiTestBegin]
15:12:03.902 INFO  [T=cq8vk8uAeIZ9RKjxp8AFd9] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:03.902 INFO  [T=cq8vk8uAeIZ9RKjxp8AFd9] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:12:04.068 INFO  [T=fzqgyWpCIx363HuYUg2UC5] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:04.068 INFO  [T=fzqgyWpCIx363HuYUg2UC5] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=eCkuaipOViHjaYdf85PPE4, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=bMPnu9Uurnige58JtJR7d0, sourceId=bMPnu9Uurnige58JtJR7d0, scenario=KafKaTestApiTestBegin]
15:12:04.068 INFO  [T=fzqgyWpCIx363HuYUg2UC5] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:04.068 INFO  [T=fzqgyWpCIx363HuYUg2UC5] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:12:04.232 INFO  [T=ggrTDyzJFeKds4gtYjTjNf] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:04.232 INFO  [T=ggrTDyzJFeKds4gtYjTjNf] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=e8n5cuNUFX19szFPq34fBs, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=dzs6UP8Z50Pf5HGmjYzYYx, sourceId=dzs6UP8Z50Pf5HGmjYzYYx, scenario=KafKaTestApiTestBegin]
15:12:04.232 INFO  [T=ggrTDyzJFeKds4gtYjTjNf] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:04.232 INFO  [T=ggrTDyzJFeKds4gtYjTjNf] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:12:04.402 INFO  [T=f8wE03etyQi9pzHL5S0lkm] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:04.402 INFO  [T=f8wE03etyQi9pzHL5S0lkm] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=f3FPJmuNpzp71VRU56V9qz, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=gph5O65sxYd19dC7JubStI, sourceId=gph5O65sxYd19dC7JubStI, scenario=KafKaTestApiTestBegin]
15:12:04.402 INFO  [T=f8wE03etyQi9pzHL5S0lkm] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:04.403 INFO  [T=f8wE03etyQi9pzHL5S0lkm] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:12:04.581 INFO  [T=fnaQBUTc4hAgeCtGaLTebR] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:04.581 INFO  [T=fnaQBUTc4hAgeCtGaLTebR] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=d538hHqQRlFgrONgJUBIMc, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=evTLBsuczyn2iY5zPNfXvc, sourceId=evTLBsuczyn2iY5zPNfXvc, scenario=KafKaTestApiTestBegin]
15:12:04.581 INFO  [T=fnaQBUTc4hAgeCtGaLTebR] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:04.581 INFO  [T=fnaQBUTc4hAgeCtGaLTebR] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:12:04.744 INFO  [T=fOBItDhNdRnfSg8VAQwXFs] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:04.744 INFO  [T=fOBItDhNdRnfSg8VAQwXFs] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=euOioWBfS7n0KUVnl9MPdi, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=dL5E0p0Cjcpa3xpffyvn45, sourceId=dL5E0p0Cjcpa3xpffyvn45, scenario=KafKaTestApiTestBegin]
15:12:04.744 INFO  [T=fOBItDhNdRnfSg8VAQwXFs] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:04.744 INFO  [T=fOBItDhNdRnfSg8VAQwXFs] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:12:04.918 INFO  [T=e4tcwaCqE3VcmI8Lhi7Jyo] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:04.918 INFO  [T=e4tcwaCqE3VcmI8Lhi7Jyo] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=gbsxfCooUzN0QPKqReNWbN, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=cVn2zPa1ed4jSBiCWAWcl5, sourceId=cVn2zPa1ed4jSBiCWAWcl5, scenario=KafKaTestApiTestBegin]
15:12:04.918 INFO  [T=e4tcwaCqE3VcmI8Lhi7Jyo] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:04.918 INFO  [T=e4tcwaCqE3VcmI8Lhi7Jyo] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:12:05.089 INFO  [T=e4cgZdqKP6E96iof66CG4o] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:05.090 INFO  [T=e4cgZdqKP6E96iof66CG4o] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=fBPxXagUuEAaQja8yWpuTG, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=cVggJgkvsEM4hemxbDpZa3, sourceId=cVggJgkvsEM4hemxbDpZa3, scenario=KafKaTestApiTestBegin]
15:12:05.090 INFO  [T=e4cgZdqKP6E96iof66CG4o] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:05.090 INFO  [T=e4cgZdqKP6E96iof66CG4o] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:12:05.251 INFO  [T=bd5Kr2btON2eNFJiijKkfM] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:05.251 INFO  [T=bd5Kr2btON2eNFJiijKkfM] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=b40Wrmloz06dJYpsUQa3kr, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=cPIqnLVZ4XFigvDTycCvo4, sourceId=cPIqnLVZ4XFigvDTycCvo4, scenario=KafKaTestApiTestBegin]
15:12:05.252 INFO  [T=bd5Kr2btON2eNFJiijKkfM] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:05.252 INFO  [T=bd5Kr2btON2eNFJiijKkfM] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:12:05.419 INFO  [T=cFlXtdF6Ou6j6c4j6qE2rO] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:05.420 INFO  [T=cFlXtdF6Ou6j6c4j6qE2rO] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=eN9yzFwi8Vf8CMrgmMSWln, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=ddhdpyMp9B2cgcQKLthz98, sourceId=ddhdpyMp9B2cgcQKLthz98, scenario=KafKaTestApiTestBegin]
15:12:05.420 INFO  [T=cFlXtdF6Ou6j6c4j6qE2rO] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:05.420 INFO  [T=cFlXtdF6Ou6j6c4j6qE2rO] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:12:05.611 INFO  [T=b32IWlIxpZK4N8Mxrynw3J] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:05.611 INFO  [T=b32IWlIxpZK4N8Mxrynw3J] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=dCiUF8oWlYFdHwAHS62aiJ, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=bEBMFpbdnqkk2KrRyDJMNV, sourceId=bEBMFpbdnqkk2KrRyDJMNV, scenario=KafKaTestApiTestBegin]
15:12:05.611 INFO  [T=b32IWlIxpZK4N8Mxrynw3J] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:05.611 INFO  [T=b32IWlIxpZK4N8Mxrynw3J] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:12:05.795 INFO  [T=fRO7T22a1aJjvKY9hNIYKp] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:05.795 INFO  [T=fRO7T22a1aJjvKY9hNIYKp] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=de3pHWPUbRrcUDoAbQUL5N, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=gsyZaFQGV0tg4H3JE4eQA2, sourceId=gsyZaFQGV0tg4H3JE4eQA2, scenario=KafKaTestApiTestBegin]
15:12:05.795 INFO  [T=fRO7T22a1aJjvKY9hNIYKp] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:05.796 INFO  [T=fRO7T22a1aJjvKY9hNIYKp] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:12:06.174 INFO  [T=fx85Jo4GILGlfsNDodJ9DY] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:06.174 INFO  [T=fx85Jo4GILGlfsNDodJ9DY] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=cq9gstYvwnucpVHVWsq8UL, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=dPgHfvzAbQM1mujIXGKSDB, sourceId=dPgHfvzAbQM1mujIXGKSDB, scenario=KafKaTestApiTestBegin]
15:12:06.174 INFO  [T=fx85Jo4GILGlfsNDodJ9DY] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:06.174 INFO  [T=fx85Jo4GILGlfsNDodJ9DY] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:12:06.176 INFO  [T=cXSUAOQIAPtft28rVGktFy] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:06.176 INFO  [T=cXSUAOQIAPtft28rVGktFy] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=gecoHDUhUyE7eeRp5UESzv, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=c0EzYP2a5EKa8rLl9jwqUi, sourceId=c0EzYP2a5EKa8rLl9jwqUi, scenario=KafKaTestApiTestBegin]
15:12:06.177 INFO  [T=cXSUAOQIAPtft28rVGktFy] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:06.177 INFO  [T=cXSUAOQIAPtft28rVGktFy] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:12:06.346 INFO  [T=eLul5xI22t9bp2EufG3GgR] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:12:06.346 INFO  [T=eLul5xI22t9bp2EufG3GgR] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=cgZoV3xFil0delO5McOIcx, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=dUyWyAJ13Aq89Ur12Rggqk, sourceId=dUyWyAJ13Aq89Ur12Rggqk, scenario=KafKaTestApiTestBegin]
15:12:06.346 INFO  [T=eLul5xI22t9bp2EufG3GgR] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:12:06.346 INFO  [T=eLul5xI22t9bp2EufG3GgR] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:14:39.240 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [KafKaTestApiTestBegin-0] for group Spring_boot_kafka_test
15:14:39.251 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:14:39.251 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [KafKaTestApiTestBegin-1] for group Spring_boot_kafka_test
15:14:39.251 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:14:39.251 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [KafKaTestApiTestBegin-2] for group Spring_boot_kafka_test
15:14:39.251 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:14:39.251 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:14:39.251 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:14:39.252 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:14:39.332 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[KafKaTestApiTestBegin-2]
15:14:39.332 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:14:40.156 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[KafKaTestApiTestBegin-0]
15:14:40.156 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:14:40.176 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[KafKaTestApiTestBegin-1]
15:14:40.176 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:14:40.186 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 10
15:14:40.186 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:14:40.186 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:14:40.186 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 10
15:14:40.186 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 10
15:14:40.186 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:14:40.186 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 10
15:14:40.186 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [KafKaTestApiTestBegin-0] for group Spring_boot_kafka_test
15:14:40.186 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:14:40.186 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:14:40.186 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:14:40.186 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 10
15:14:40.186 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:14:40.186 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:14:40.194 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[KafKaTestApiTestBegin-0]
15:14:41.905 INFO  [T=d6AaYo0Jbcj3Agg00L8ngX] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:14:41.905 INFO  [T=d6AaYo0Jbcj3Agg00L8ngX] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=eSGcs321slA31c7wnm0uaH, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=cBmeLjcjnKPeP3F5xqgMqm, sourceId=cBmeLjcjnKPeP3F5xqgMqm, scenario=KafKaTestApiTestBegin]
15:14:41.906 INFO  [T=d6AaYo0Jbcj3Agg00L8ngX] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:14:41.906 INFO  [T=d6AaYo0Jbcj3Agg00L8ngX] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:14:42.641 INFO  [T=eIkLKa09khjlmetwZq8vCy] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:14:42.641 INFO  [T=eIkLKa09khjlmetwZq8vCy] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=dwJU7bM1x0S53hMjAduziX, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=eCSbc2vLjwf96ieGbjr7iq, sourceId=eCSbc2vLjwf96ieGbjr7iq, scenario=KafKaTestApiTestBegin]
15:14:42.641 INFO  [T=eIkLKa09khjlmetwZq8vCy] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:14:42.641 INFO  [T=eIkLKa09khjlmetwZq8vCy] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:14:43.139 INFO  [T=f8zy7TJLKT54uKnoB6GuDW] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:14:43.139 INFO  [T=f8zy7TJLKT54uKnoB6GuDW] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=bqI9IJLzfmGjEXhCZ5QYiA, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=boEwC2qMYaClqOkkp3Z5sl, sourceId=boEwC2qMYaClqOkkp3Z5sl, scenario=KafKaTestApiTestBegin]
15:14:43.139 INFO  [T=f8zy7TJLKT54uKnoB6GuDW] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:14:43.139 INFO  [T=f8zy7TJLKT54uKnoB6GuDW] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:14:44.111 INFO  [T=eXx0frKE2PucUPHxFa8dmo] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:14:44.111 INFO  [T=eXx0frKE2PucUPHxFa8dmo] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=cwT9xiecN7G2VqGLLczU4f, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=dlQbkqDCQlBhkzwwijhfQC, sourceId=dlQbkqDCQlBhkzwwijhfQC, scenario=KafKaTestApiTestBegin]
15:14:44.111 INFO  [T=eXx0frKE2PucUPHxFa8dmo] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:14:44.111 INFO  [T=eXx0frKE2PucUPHxFa8dmo] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:14:44.680 INFO  [T=epaVKB9Yvom3NB0lDdf7xc] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:14:44.680 INFO  [T=epaVKB9Yvom3NB0lDdf7xc] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=f8FBfZVbzAadO5apuKTndU, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=ecM6syZaH9tfkGJuiZEr44, sourceId=ecM6syZaH9tfkGJuiZEr44, scenario=KafKaTestApiTestBegin]
15:14:44.680 INFO  [T=epaVKB9Yvom3NB0lDdf7xc] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:14:44.680 INFO  [T=epaVKB9Yvom3NB0lDdf7xc] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:14:45.159 INFO  [T=cd0L0eSIky12fQScZMD0IN] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:14:45.160 INFO  [T=cd0L0eSIky12fQScZMD0IN] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=bJdu6b0JnU4irMe5yd1cU4, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=c0lHLw8Nh0P80rABPifmcK, sourceId=c0lHLw8Nh0P80rABPifmcK, scenario=KafKaTestApiTestBegin]
15:14:45.160 INFO  [T=cd0L0eSIky12fQScZMD0IN] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:14:45.160 INFO  [T=cd0L0eSIky12fQScZMD0IN] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:14:45.689 INFO  [T=bie4QmwnCo64SEPJ64wovB] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:14:45.689 INFO  [T=bie4QmwnCo64SEPJ64wovB] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=crELTd9cWqF03B8zdsgAyV, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=cJeVuyCTwLn8YVIbzSlNp3, sourceId=cJeVuyCTwLn8YVIbzSlNp3, scenario=KafKaTestApiTestBegin]
15:14:45.689 INFO  [T=bie4QmwnCo64SEPJ64wovB] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:14:45.689 INFO  [T=bie4QmwnCo64SEPJ64wovB] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:14:46.201 INFO  [T=bv9rHdIO7MH1Oaaq06vQJY] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:14:46.201 INFO  [T=bv9rHdIO7MH1Oaaq06vQJY] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=cJJR9Kr3I70lin1njLFcOr, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=dvTFWsWRLfy3bcOrdu0KuA, sourceId=dvTFWsWRLfy3bcOrdu0KuA, scenario=KafKaTestApiTestBegin]
15:14:46.201 INFO  [T=bv9rHdIO7MH1Oaaq06vQJY] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:14:46.202 INFO  [T=bv9rHdIO7MH1Oaaq06vQJY] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:14:46.720 INFO  [T=c8ItfHsjWOI2Bkx0OCgO06] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:14:46.721 INFO  [T=c8ItfHsjWOI2Bkx0OCgO06] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=dwrBbYGYtEc2u90zbkSMRy, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=dLqMesT5Zt29VkcO8GKKRC, sourceId=dLqMesT5Zt29VkcO8GKKRC, scenario=KafKaTestApiTestBegin]
15:14:46.721 INFO  [T=c8ItfHsjWOI2Bkx0OCgO06] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:14:46.721 INFO  [T=c8ItfHsjWOI2Bkx0OCgO06] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:14:47.240 INFO  [T=d5TZV81AwYCdH0VdA2izEA] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:14:47.241 INFO  [T=d5TZV81AwYCdH0VdA2izEA] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=dIA5NTep7D08RhfCW0uSwz, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=cEpek581LnAeDm3BWRz8wj, sourceId=cEpek581LnAeDm3BWRz8wj, scenario=KafKaTestApiTestBegin]
15:14:47.241 INFO  [T=d5TZV81AwYCdH0VdA2izEA] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:14:47.241 INFO  [T=d5TZV81AwYCdH0VdA2izEA] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:14:47.790 INFO  [T=fGvdPVP37jplpfX3QzY0w2] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:14:47.790 INFO  [T=fGvdPVP37jplpfX3QzY0w2] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=ddWx3owIhMBfgFUrPyRPmw, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=c5CNuvPlw1Mfjq8dITThys, sourceId=c5CNuvPlw1Mfjq8dITThys, scenario=KafKaTestApiTestBegin]
15:14:47.790 INFO  [T=fGvdPVP37jplpfX3QzY0w2] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:14:47.790 INFO  [T=fGvdPVP37jplpfX3QzY0w2] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[0ms] Result[{"soleCode":"DS01"}]
15:14:48.316 INFO  [T=ffoF5LUgrBBcjgorGYOd0L] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:14:48.316 INFO  [T=ffoF5LUgrBBcjgorGYOd0L] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=f8XMrpyPGcl09MShQx1ory, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=erggVsfUr5wjo6emaCEQdc, sourceId=erggVsfUr5wjo6emaCEQdc, scenario=KafKaTestApiTestBegin]
15:14:48.317 INFO  [T=ffoF5LUgrBBcjgorGYOd0L] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:14:48.317 INFO  [T=ffoF5LUgrBBcjgorGYOd0L] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:14:48.824 INFO  [T=bsIUoQe17F8fZZ0mZEAcOu] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:14:48.825 INFO  [T=bsIUoQe17F8fZZ0mZEAcOu] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=gav7D4Y0in2l5skfxO2FLM, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=bJW7BYwCBbj78J8RZpU6t9, sourceId=bJW7BYwCBbj78J8RZpU6t9, scenario=KafKaTestApiTestBegin]
15:14:48.825 INFO  [T=bsIUoQe17F8fZZ0mZEAcOu] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:14:48.825 INFO  [T=bsIUoQe17F8fZZ0mZEAcOu] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:14:49.342 INFO  [T=gnbbhQkEy0Ff1pvM8vvTsX] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:14:49.342 INFO  [T=gnbbhQkEy0Ff1pvM8vvTsX] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=cdvpDHtGOJ1fvgzwdiTcY2, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=dr0qCuDrS1w9mcqZCuyRUh, sourceId=dr0qCuDrS1w9mcqZCuyRUh, scenario=KafKaTestApiTestBegin]
15:14:49.342 INFO  [T=gnbbhQkEy0Ff1pvM8vvTsX] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:14:49.343 INFO  [T=gnbbhQkEy0Ff1pvM8vvTsX] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:14:49.849 INFO  [T=f6Wfaqb9oCyeEzeveSZt4C] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:14:49.849 INFO  [T=f6Wfaqb9oCyeEzeveSZt4C] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=f2xunwfHDzbez8tWjDAz61, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=g2yR2HhhcamifYzQE42Uwq, sourceId=g2yR2HhhcamifYzQE42Uwq, scenario=KafKaTestApiTestBegin]
15:14:49.850 INFO  [T=f6Wfaqb9oCyeEzeveSZt4C] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:14:49.850 INFO  [T=f6Wfaqb9oCyeEzeveSZt4C] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:15:39.471 INFO  [T=d1aFPuM1hVBhC1GmYAyo9X] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:15:39.472 INFO  [T=d1aFPuM1hVBhC1GmYAyo9X] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=cONIesKKMw0joLTtRxv278, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=e1sYsKZt67mhL4IYeh4ia7, sourceId=e1sYsKZt67mhL4IYeh4ia7, scenario=KafKaTestApiTestBegin]
15:15:39.472 INFO  [T=d1aFPuM1hVBhC1GmYAyo9X] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:15:39.472 INFO  [T=d1aFPuM1hVBhC1GmYAyo9X] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[1ms] Result[{"soleCode":"DS01"}]
15:16:34.376 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:16:34.376 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:16:34.376 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:16:34.389 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:16:34.389 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:16:34.389 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:16:34.389 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:16:34.389 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [KafKaTestApiTestBegin-0] for group Spring_boot_kafka_test
15:16:34.389 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:16:34.389 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:16:34.406 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:16:34.406 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:16:34.406 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:16:34.811 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[KafKaTestApiTestBegin-0]
15:16:34.811 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:16:35.045 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 11
15:16:35.045 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 11
15:16:35.045 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 11
15:16:35.045 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 11
15:16:35.045 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 11
15:16:35.045 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:16:35.045 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [KafKaTestApiTestBegin-1] for group Spring_boot_kafka_test
15:16:35.045 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [KafKaTestApiTestBegin-2] for group Spring_boot_kafka_test
15:16:35.045 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [KafKaTestApiTestBegin-0] for group Spring_boot_kafka_test
15:16:35.045 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:16:35.045 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:16:35.045 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:16:35.045 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[KafKaTestApiTestBegin-0]
15:16:35.045 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[KafKaTestApiTestBegin-1]
15:16:35.045 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[KafKaTestApiTestBegin-2]
15:17:07.886 INFO  [] StartupInfoLogger.logStarting:48 Starting Runner on DS-TS-0358 with PID 9416 (D:\Workspace\spring_boot_kafka_test\bin started by ex-songdeshun in D:\Workspace\spring_boot_kafka_test)
15:17:07.976 INFO  [] SpringApplication.logStartupProfileInfo:659 No active profile set, falling back to default profiles: default
15:17:08.161 INFO  [] AbstractApplicationContext.prepareRefresh:581 Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@46944ca9: startup date [Wed Sep 27 15:17:08 CST 2017]; root of context hierarchy
15:17:09.373 WARN  [] AutoProxyRegistrar.registerBeanDefinitions:79 AutoProxyRegistrar was imported but no annotations were found having both 'mode' and 'proxyTargetClass' attributes of type AdviceMode and boolean respectively. This means that auto proxy creator registration and configuration may not have occurred as intended, and components may not be proxied as expected. Check to ensure that AutoProxyRegistrar has been @Import'ed on the same class where these annotations are declared; otherwise remove the import of AutoProxyRegistrar altogether.
15:17:09.678 INFO  [] RepositoryConfigurationDelegate.multipleStoresDetected:166 Multiple Spring Data modules found, entering strict repository configuration mode!
15:17:09.728 INFO  [] RepositoryConfigurationDelegate.multipleStoresDetected:166 Multiple Spring Data modules found, entering strict repository configuration mode!
15:17:09.968 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'com.dashuf.core.common.configuration.CommonConfiguration' of type [class com.dashuf.core.common.configuration.CommonConfiguration$$EnhancerBySpringCGLIB$$e489c05b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:17:09.988 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'com.dashuf.core.event.configuration.EventConfiguration' of type [class com.dashuf.core.event.configuration.EventConfiguration$$EnhancerBySpringCGLIB$$41c3a493] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:17:09.998 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [class org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$15662838] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:17:10.078 INFO  [] PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization:328 Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$41b416b5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15:17:10.468 INFO  [] Xnio.<clinit>:99 XNIO version 3.3.6.Final
15:17:10.482 INFO  [] NioXnio.<clinit>:55 XNIO NIO Implementation Version 3.3.6.Final
15:17:10.562 WARN  [] Bootstrap.handleDeployment:67 UT026009: XNIO worker was not set on WebSocketDeploymentInfo, the default worker will be used
15:17:10.562 WARN  [] Bootstrap.handleDeployment:76 UT026010: Buffer pool was not set on WebSocketDeploymentInfo, the default pool will be used
15:17:10.572 INFO  [] ServletContextImpl.log:313 Initializing Spring embedded WebApplicationContext
15:17:10.572 INFO  [] EmbeddedWebApplicationContext.prepareEmbeddedWebApplicationContext:276 Root WebApplicationContext: initialization completed in 2411 ms
15:17:10.852 INFO  [] ServletRegistrationBean.onStartup:190 Mapping servlet: 'dispatcherServlet' to [/]
15:17:10.852 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'metricFilter' to: [/*]
15:17:10.852 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'characterEncodingFilter' to: [/*]
15:17:10.852 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
15:17:10.852 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'httpPutFormContentFilter' to: [/*]
15:17:10.852 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'requestContextFilter' to: [/*]
15:17:10.852 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'webRequestLoggingFilter' to: [/*]
15:17:10.852 INFO  [] AbstractFilterRegistrationBean.configure:258 Mapping filter: 'applicationContextIdFilter' to: [/*]
15:17:11.132 INFO  [] LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory:334 Building JPA container EntityManagerFactory for persistence unit 'default'
15:17:11.152 INFO  [] LogHelper.logPersistenceUnitInformation:31 HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
15:17:11.212 INFO  [] Version.logVersion:37 HHH000412: Hibernate Core {5.0.9.Final}
15:17:11.212 INFO  [] Environment.<clinit>:213 HHH000206: hibernate.properties not found
15:17:11.212 INFO  [] Environment.buildBytecodeProvider:317 HHH000021: Bytecode provider name : javassist
15:17:11.252 INFO  [] JavaReflectionManager.<clinit>:66 HCANN000001: Hibernate Commons Annotations {5.0.1.Final}
15:17:11.647 INFO  [] Dialect.<init>:156 HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
15:17:11.825 INFO  [] SchemaValidator.validate:69 HHH000229: Running schema validator
15:17:11.855 INFO  [] AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory:382 Initialized JPA EntityManagerFactory for persistence unit 'default'
15:17:11.985 WARN  [] ServiceInstance.init:87 Instance name is empty, IP[10.1.113.233] will instead of it.
15:17:12.425 INFO  [] RequestMappingHandlerAdapter.initControllerAdviceCache:534 Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@46944ca9: startup date [Wed Sep 27 15:17:08 CST 2017]; root of context hierarchy
15:17:12.515 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
15:17:12.515 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
15:17:12.568 INFO  [] AbstractUrlHandlerMapping.registerHandler:354 Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
15:17:12.568 INFO  [] AbstractUrlHandlerMapping.registerHandler:354 Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
15:17:12.618 INFO  [] AbstractUrlHandlerMapping.registerHandler:354 Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
15:17:13.063 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:17:13.064 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:17:13.065 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
15:17:13.066 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:17:13.067 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:17:13.067 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/health || /health.json],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(java.security.Principal)
15:17:13.068 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:17:13.069 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
15:17:13.070 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:17:13.071 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:17:13.073 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/info || /info.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:17:13.074 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
15:17:13.075 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
15:17:13.075 INFO  [] AbstractHandlerMethodMapping$MappingRegistry.register:543 Mapped "{[/env || /env.json],methods=[GET],produces=[application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
15:17:13.325 WARN  [] RedisStarterDeprecationWarningAutoConfiguration.logWarning:43 spring-boot-starter-redis is deprecated as of Spring Boot 1.4, please migrate to spring-boot-starter-data-redis
15:17:13.516 INFO  [] MBeanExporter.afterSingletonsInstantiated:431 Registering beans for JMX exposure on startup
15:17:13.527 INFO  [] DefaultLifecycleProcessor$LifecycleGroup.start:341 Starting beans in phase 0
15:17:13.543 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:17:13.566 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:17:13.582 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:17:13.583 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:17:13.586 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:17:13.590 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:17:13.592 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:17:13.593 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:17:13.594 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:17:13.596 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:17:13.600 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:17:13.600 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:17:13.602 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:17:13.604 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:17:13.605 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:17:13.606 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:17:13.606 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:17:13.608 INFO  [] AbstractConfig.logAll:178 ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = Spring_boot_kafka_test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

15:17:13.612 INFO  [] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:17:13.613 INFO  [] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:17:13.669 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:17:13.669 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:17:13.685 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:17:13.685 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:17:13.763 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:17:13.764 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:17:13.764 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:17:13.764 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:17:13.764 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:17:13.765 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:17:13.765 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:17:13.765 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:17:13.765 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:17:13.765 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:17:13.766 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:17:13.766 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:17:13.768 INFO  [] AbstractCoordinator.handleGroupMetadataResponse:505 Discovered coordinator 10.1.105.30:9092 (id: 2147483647 rack: null) for group Spring_boot_kafka_test.
15:17:13.768 INFO  [] ConsumerCoordinator.onJoinPrepare:292 Revoking previously assigned partitions [] for group Spring_boot_kafka_test
15:17:13.769 INFO  [] AbstractMessageListenerContainer$2.onPartitionsRevoked:242 partitions revoked:[]
15:17:13.769 INFO  [] AbstractCoordinator.sendJoinGroupRequest:326 (Re-)joining group Spring_boot_kafka_test
15:17:13.881 INFO  [] UndertowEmbeddedServletContainer.start:214 Undertow started on port(s) 9050 (http)
15:17:13.891 INFO  [] StartupInfoLogger.logStarted:57 Started Runner in 6.846 seconds (JVM running for 7.467)
15:17:15.901 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 16
15:17:15.902 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:17:15.906 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 16
15:17:15.906 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:17:15.907 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 16
15:17:15.907 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [KafKaTestApiTestBegin-0] for group Spring_boot_kafka_test
15:17:15.909 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 16
15:17:15.910 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [KafKaTestApiTestBegin-2] for group Spring_boot_kafka_test
15:17:15.910 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:17:15.910 INFO  [] AbstractCoordinator$SyncGroupResponseHandler.handle:434 Successfully joined group Spring_boot_kafka_test with generation 16
15:17:15.910 INFO  [] ConsumerCoordinator.onJoinComplete:231 Setting newly assigned partitions [] for group Spring_boot_kafka_test
15:17:15.910 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:17:15.911 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[]
15:17:15.920 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[KafKaTestApiTestBegin-0]
15:17:15.922 INFO  [] AbstractMessageListenerContainer$2.onPartitionsAssigned:247 partitions assigned:[KafKaTestApiTestBegin-2]
15:17:36.114 INFO  [T=cVcWXsOYdmRkpdE6qNzDi7] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:17:36.114 INFO  [T=cVcWXsOYdmRkpdE6qNzDi7] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=fNNBVJtp7ZHkG34YDlIn9v, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=gsJkB3lVtbp269q8gfDedq, sourceId=gsJkB3lVtbp269q8gfDedq, scenario=KafKaTestApiTestBegin]
15:17:40.514 INFO  [T=cVcWXsOYdmRkpdE6qNzDi7] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:17:40.515 INFO  [T=cVcWXsOYdmRkpdE6qNzDi7] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[4401ms] Result[{"soleCode":"DS01"}]
15:17:40.529 INFO  [T=cVcWXsOYdmRkpdE6qNzDi7] AbstractConfig.logAll:178 ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 1

15:17:40.539 INFO  [T=cVcWXsOYdmRkpdE6qNzDi7] AbstractConfig.logAll:178 ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [kafka1.intsit.dsfdc.com:9092, kafka2.intsit.dsfdc.com:9092, kafka3.intsit.dsfdc.com:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 1

15:17:40.540 INFO  [T=cVcWXsOYdmRkpdE6qNzDi7] AppInfoParser$AppInfo.<init>:83 Kafka version : 0.10.0.1
15:17:40.540 INFO  [T=cVcWXsOYdmRkpdE6qNzDi7] AppInfoParser$AppInfo.<init>:84 Kafka commitId : a7a17cdec9eaa6c5
15:18:05.789 INFO  [T=cBAdyf33wE7lUztiDPs41p] EventMessageListener.invokeEvent:54 ##### Begin Event[KafKaTestApiTestBegin] Param[[DS01]]
15:18:05.789 INFO  [T=cBAdyf33wE7lUztiDPs41p] EventMessageListener.invokeEvent:56 ##### Event[KafKaTestApiTestBegin] CallInfo[msgId=gtKUly26YZg0Y92UrHRlRw, user=UNKNOWN, caller=Spring_boot_kafka_test2, callerId=fMPsOB4Evodhen4c9UodZa, sourceId=fMPsOB4Evodhen4c9UodZa, scenario=KafKaTestApiTestBegin]
15:18:10.661 INFO  [T=cBAdyf33wE7lUztiDPs41p] KafKaTestApi.dataDictionaryDetailBegin:33 数据字典-详情查询参数：{"soleCode":"DS01"}
15:18:10.661 INFO  [T=cBAdyf33wE7lUztiDPs41p] EventMessageListener.invokeEvent:66 ##### Finish Event[KafKaTestApiTestBegin] Cost[4872ms] Result[{"soleCode":"DS01"}]
